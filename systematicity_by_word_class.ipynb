{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Systematicity in English monomorphemic words by word class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sean Trott"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do certain word classes have more sub-morphemic systematicity than others?\n",
    "\n",
    "**TO DO**:\n",
    "* Use Levenshtein distance over phonemes, instead of orthography\n",
    "* Relate to word features: grammatical class, AoA, Concreteness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import gensim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Variables\n",
    "MODEL_PATH = os.environ['WORD2VEC_PATH']\n",
    "ROOT_PATH = 'data/raw/roots_celex_monosyllabic.txt'\n",
    "\n",
    "LOAD_MODEL = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.KeyedVectors.load_word2vec_format(MODEL_PATH, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "entries = open(ROOT_PATH, \"r\").read().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = [entry.split(\"\\\\\")[0] for entry in entries if entry != \"\" and entry.islower()]\n",
    "words[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter by words that appear in model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "critical_words = list(set([w for w in words if w in model.vocab]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2082"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(critical_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain form and meaning similarity metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we import the class `SystematicityUtilities` from a [custom library](https://github.com/seantrott/nlp_utilities). By default, this class uses *Levenshtein distance* as its metric for *form similarity*, and *cosine similarity* as its metric for *meaning similarity*. The `compare_form_and_meaning` method used below compares every word pair along form and meaning dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlp_utilities.compling import SystematicityUtilities\n",
    "systematicity_utils = SystematicityUtilities(model)\n",
    "comparisons = systematicity_utils.compare_form_and_meaning(critical_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparisons_df = pd.DataFrame.from_dict(comparisons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2166321 comparisons total\n"
     ]
    }
   ],
   "source": [
    "print(\"{length} comparisons total\".format(length=len(comparisons_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>form</th>\n",
       "      <th>meaning</th>\n",
       "      <th>w1</th>\n",
       "      <th>w2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2112509</th>\n",
       "      <td>1</td>\n",
       "      <td>0.293345</td>\n",
       "      <td>trope</td>\n",
       "      <td>tripe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652174</th>\n",
       "      <td>1</td>\n",
       "      <td>0.235669</td>\n",
       "      <td>sake</td>\n",
       "      <td>save</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2083455</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.046745</td>\n",
       "      <td>stale</td>\n",
       "      <td>scale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1194772</th>\n",
       "      <td>1</td>\n",
       "      <td>0.187018</td>\n",
       "      <td>sword</td>\n",
       "      <td>word</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1884214</th>\n",
       "      <td>1</td>\n",
       "      <td>0.069826</td>\n",
       "      <td>ha</td>\n",
       "      <td>hat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1719650</th>\n",
       "      <td>1</td>\n",
       "      <td>0.042543</td>\n",
       "      <td>roe</td>\n",
       "      <td>re</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2083484</th>\n",
       "      <td>1</td>\n",
       "      <td>0.107657</td>\n",
       "      <td>stale</td>\n",
       "      <td>stalk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2083453</th>\n",
       "      <td>1</td>\n",
       "      <td>0.060719</td>\n",
       "      <td>stale</td>\n",
       "      <td>stage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2129726</th>\n",
       "      <td>1</td>\n",
       "      <td>0.031586</td>\n",
       "      <td>sans</td>\n",
       "      <td>sands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2083488</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.002093</td>\n",
       "      <td>stale</td>\n",
       "      <td>stile</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         form   meaning     w1     w2\n",
       "2112509     1  0.293345  trope  tripe\n",
       "652174      1  0.235669   sake   save\n",
       "2083455     1 -0.046745  stale  scale\n",
       "1194772     1  0.187018  sword   word\n",
       "1884214     1  0.069826     ha    hat\n",
       "1719650     1  0.042543    roe     re\n",
       "2083484     1  0.107657  stale  stalk\n",
       "2083453     1  0.060719  stale  stage\n",
       "2129726     1  0.031586   sans  sands\n",
       "2083488     1 -0.002093  stale  stile"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparisons_df.sort_values('form').head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import linregress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r=-0.04067261287952155, p=0.0\n"
     ]
    }
   ],
   "source": [
    "true_regression = linregress(comparisons_df['form'], comparisons_df['meaning'])\n",
    "print(\"r={r}, p={p}\".format(r=true_regression.rvalue, p=true_regression.pvalue))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In other words, words with higher **form distance** (e.g. a higher Levenshtein distance) will have smaller **meaning similarity** (e.g. cosine similarity)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare global correlation to permuted distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "permuted_results = []\n",
    "for permute in range(10):\n",
    "    permuted_meaning = np.random.permutation(comparisons_df['meaning'])\n",
    "    random_regression = linregress(comparisons_df['form'], permuted_meaning)\n",
    "    permuted_results.append(random_regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "permuted_cors = [reg.rvalue for reg in permuted_results]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can compare the *true correlation* with the distribution of correlations obtained by shuffling our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "greater = [cor for cor in permuted_cors if cor <= true_regression.rvalue]\n",
    "p_global = len(greater) / len(permuted_cors)\n",
    "p_global"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Systematicity coefficients for each word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can use leave-one-out regression to determine how each word contributes to the overall correlation. For each word, we remove all comparisons involving that word, then take the global correlation again, and compare that score to the original correlation. This follows the procedure in [Monaghan et al, 2014](http://rstb.royalsocietypublishing.org/content/369/1651/20130299.short).\n",
    "\n",
    "Recall that **original** was negative. So if **original** - **new** is negative, that means that removing the word results in a *lower* correlation (e.g. closer to 0), which suggests that the word provided a source of **form-meaning systematicity** to the correlation.\n",
    "\n",
    "If **original** - **new** is positive, that means that removing the word results in a *higher* correlation (e.g. further from 0), which suggests that the word provided a source of **form-meaning arbitrariness** to the correlation.\n",
    "\n",
    "Thus:\n",
    "* **Negative** impact values suggest a word is more systematic\n",
    "* **Positive** impact values suggest a word is more arbitrary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_systematicity = {\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0% done...\n",
      "1.0% done...\n",
      "1.0% done...\n",
      "2.0% done...\n",
      "2.0% done...\n",
      "3.0% done...\n",
      "3.0% done...\n",
      "4.0% done...\n",
      "4.0% done...\n",
      "5.0% done...\n",
      "5.0% done...\n",
      "6.0% done...\n",
      "6.0% done...\n",
      "7.000000000000001% done...\n",
      "7.000000000000001% done...\n",
      "8.0% done...\n",
      "8.0% done...\n",
      "9.0% done...\n",
      "9.0% done...\n",
      "10.0% done...\n",
      "10.0% done...\n",
      "11.0% done...\n",
      "11.0% done...\n",
      "12.0% done...\n",
      "12.0% done...\n",
      "12.0% done...\n",
      "13.0% done...\n",
      "13.0% done...\n",
      "14.000000000000002% done...\n",
      "14.000000000000002% done...\n",
      "15.0% done...\n",
      "15.0% done...\n",
      "16.0% done...\n",
      "16.0% done...\n",
      "17.0% done...\n",
      "17.0% done...\n",
      "18.0% done...\n",
      "18.0% done...\n",
      "19.0% done...\n",
      "19.0% done...\n",
      "20.0% done...\n",
      "20.0% done...\n",
      "21.0% done...\n",
      "21.0% done...\n",
      "22.0% done...\n",
      "22.0% done...\n",
      "23.0% done...\n",
      "23.0% done...\n",
      "24.0% done...\n",
      "24.0% done...\n",
      "24.0% done...\n",
      "25.0% done...\n",
      "25.0% done...\n",
      "26.0% done...\n",
      "26.0% done...\n",
      "27.0% done...\n",
      "27.0% done...\n",
      "28.000000000000004% done...\n",
      "28.000000000000004% done...\n",
      "28.999999999999996% done...\n",
      "28.999999999999996% done...\n",
      "30.0% done...\n",
      "30.0% done...\n",
      "31.0% done...\n",
      "31.0% done...\n",
      "32.0% done...\n",
      "32.0% done...\n",
      "33.0% done...\n",
      "33.0% done...\n",
      "34.0% done...\n",
      "34.0% done...\n",
      "35.0% done...\n",
      "35.0% done...\n",
      "36.0% done...\n",
      "36.0% done...\n",
      "37.0% done...\n",
      "37.0% done...\n",
      "37.0% done...\n",
      "38.0% done...\n",
      "38.0% done...\n",
      "39.0% done...\n",
      "39.0% done...\n",
      "40.0% done...\n",
      "40.0% done...\n",
      "41.0% done...\n",
      "41.0% done...\n",
      "42.0% done...\n",
      "42.0% done...\n",
      "43.0% done...\n",
      "43.0% done...\n",
      "44.0% done...\n",
      "44.0% done...\n",
      "45.0% done...\n",
      "45.0% done...\n",
      "46.0% done...\n",
      "46.0% done...\n",
      "47.0% done...\n",
      "47.0% done...\n",
      "48.0% done...\n",
      "48.0% done...\n",
      "49.0% done...\n",
      "49.0% done...\n",
      "49.0% done...\n",
      "50.0% done...\n",
      "50.0% done...\n",
      "51.0% done...\n",
      "51.0% done...\n",
      "52.0% done...\n",
      "52.0% done...\n",
      "53.0% done...\n",
      "53.0% done...\n",
      "54.0% done...\n",
      "54.0% done...\n",
      "55.00000000000001% done...\n",
      "55.00000000000001% done...\n",
      "56.00000000000001% done...\n",
      "56.00000000000001% done...\n",
      "56.99999999999999% done...\n",
      "56.99999999999999% done...\n",
      "57.99999999999999% done...\n",
      "57.99999999999999% done...\n",
      "59.0% done...\n",
      "59.0% done...\n",
      "60.0% done...\n",
      "60.0% done...\n",
      "61.0% done...\n",
      "61.0% done...\n",
      "61.0% done...\n",
      "62.0% done...\n",
      "62.0% done...\n",
      "63.0% done...\n",
      "63.0% done...\n",
      "64.0% done...\n",
      "64.0% done...\n",
      "65.0% done...\n",
      "65.0% done...\n",
      "66.0% done...\n",
      "66.0% done...\n",
      "67.0% done...\n",
      "67.0% done...\n",
      "68.0% done...\n",
      "68.0% done...\n",
      "69.0% done...\n",
      "69.0% done...\n",
      "70.0% done...\n",
      "70.0% done...\n",
      "71.0% done...\n",
      "71.0% done...\n",
      "72.0% done...\n",
      "72.0% done...\n",
      "73.0% done...\n",
      "73.0% done...\n",
      "73.0% done...\n",
      "74.0% done...\n",
      "74.0% done...\n",
      "75.0% done...\n",
      "75.0% done...\n",
      "76.0% done...\n",
      "76.0% done...\n",
      "77.0% done...\n",
      "77.0% done...\n",
      "78.0% done...\n",
      "78.0% done...\n",
      "79.0% done...\n",
      "79.0% done...\n",
      "80.0% done...\n",
      "80.0% done...\n",
      "81.0% done...\n",
      "81.0% done...\n",
      "82.0% done...\n",
      "82.0% done...\n",
      "83.0% done...\n",
      "83.0% done...\n",
      "84.0% done...\n",
      "84.0% done...\n",
      "85.0% done...\n",
      "85.0% done...\n",
      "85.0% done...\n",
      "86.0% done...\n",
      "86.0% done...\n",
      "87.0% done...\n",
      "87.0% done...\n",
      "88.0% done...\n",
      "88.0% done...\n",
      "89.0% done...\n",
      "89.0% done...\n",
      "90.0% done...\n",
      "90.0% done...\n",
      "91.0% done...\n",
      "91.0% done...\n",
      "92.0% done...\n",
      "92.0% done...\n",
      "93.0% done...\n",
      "93.0% done...\n",
      "94.0% done...\n",
      "94.0% done...\n",
      "95.0% done...\n",
      "95.0% done...\n",
      "96.0% done...\n",
      "96.0% done...\n",
      "97.0% done...\n",
      "97.0% done...\n",
      "98.0% done...\n",
      "98.0% done...\n",
      "98.0% done...\n",
      "99.0% done...\n",
      "99.0% done...\n",
      "100.0% done...\n"
     ]
    }
   ],
   "source": [
    "index = 1\n",
    "for word in critical_words:\n",
    "    if index % 100 == 0:\n",
    "        print(\"{pct}% done...\".format(pct=round(index/len(critical_words), 2)*100))\n",
    "    df_copy = comparisons_df[(comparisons_df['w1'] != word) & (comparisons_df['w2'] != word)]\n",
    "    new_correlation = linregress(df_copy['form'], df_copy['meaning'])\n",
    "    word_to_systematicity[word] = true_regression.rvalue - new_correlation.rvalue\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2082"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_to_systematicity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_systematicity_df = pd.DataFrame.from_dict({'word': list(word_to_systematicity.keys()),\n",
    "                                                 'impact': list(word_to_systematicity.values())})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>impact</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>dark</td>\n",
       "      <td>-0.041383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949</th>\n",
       "      <td>wold</td>\n",
       "      <td>-0.041370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>price</td>\n",
       "      <td>-0.041344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1699</th>\n",
       "      <td>wave</td>\n",
       "      <td>-0.041352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word    impact\n",
       "20     dark -0.041383\n",
       "949    wold -0.041370\n",
       "474   price -0.041344\n",
       "1699   wave -0.041352"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_systematicity_df.sample(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_systematicity_df['word_length'] = words_systematicity_df['word'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>impact</th>\n",
       "      <th>word_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1858</th>\n",
       "      <td>tray</td>\n",
       "      <td>-0.041356</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>stark</td>\n",
       "      <td>-0.041328</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>brawl</td>\n",
       "      <td>-0.041373</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1207</th>\n",
       "      <td>dam</td>\n",
       "      <td>-0.041332</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word    impact  word_length\n",
       "1858   tray -0.041356            4\n",
       "630   stark -0.041328            5\n",
       "294   brawl -0.041373            5\n",
       "1207    dam -0.041332            3"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_systematicity_df.sample(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>impact</td>      <th>  R-squared:         </th>  <td>   0.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>  -0.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>  0.1737</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 04 Sep 2018</td> <th>  Prob (F-statistic):</th>   <td> 0.677</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>13:35:52</td>     <th>  Log-Likelihood:    </th>  <td>  19504.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  2082</td>      <th>  AIC:               </th> <td>-3.900e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  2080</td>      <th>  BIC:               </th> <td>-3.899e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>   <td>   -0.0413</td> <td> 2.06e-06</td> <td>-2.01e+04</td> <td> 0.000</td> <td>   -0.041</td> <td>   -0.041</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>word_length</th> <td> 1.924e-07</td> <td> 4.62e-07</td> <td>    0.417</td> <td> 0.677</td> <td>-7.13e-07</td> <td>  1.1e-06</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>13.379</td> <th>  Durbin-Watson:     </th> <td>   1.926</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  18.969</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.004</td> <th>  Prob(JB):          </th> <td>7.60e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.468</td> <th>  Cond. No.          </th> <td>    21.3</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                 impact   R-squared:                       0.000\n",
       "Model:                            OLS   Adj. R-squared:                 -0.000\n",
       "Method:                 Least Squares   F-statistic:                    0.1737\n",
       "Date:                Tue, 04 Sep 2018   Prob (F-statistic):              0.677\n",
       "Time:                        13:35:52   Log-Likelihood:                 19504.\n",
       "No. Observations:                2082   AIC:                        -3.900e+04\n",
       "Df Residuals:                    2080   BIC:                        -3.899e+04\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===============================================================================\n",
       "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------\n",
       "Intercept      -0.0413   2.06e-06  -2.01e+04      0.000      -0.041      -0.041\n",
       "word_length  1.924e-07   4.62e-07      0.417      0.677   -7.13e-07     1.1e-06\n",
       "==============================================================================\n",
       "Omnibus:                       13.379   Durbin-Watson:                   1.926\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               18.969\n",
       "Skew:                          -0.004   Prob(JB):                     7.60e-05\n",
       "Kurtosis:                       3.468   Cond. No.                         21.3\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ols(\"impact ~ word_length\", words_systematicity_df).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write data to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparisons_df.to_csv(\"data/processed/wordpair_comparisons.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_systematicity_df.to_csv(\"data/processed/all_words_systematicity.csv\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
