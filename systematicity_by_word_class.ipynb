{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Systematicity in English monomorphemic words by word class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sean Trott"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do certain word classes have more sub-morphemic systematicity than others?\n",
    "\n",
    "**TO DO**:\n",
    "* Use Levenshtein distance over phonemes, instead of orthography\n",
    "* Relate to word features: grammatical class, AoA, Concreteness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import gensim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Variables\n",
    "MODEL_PATH = os.environ['WORD2VEC_PATH']\n",
    "ROOT_PATH = 'data/raw/roots_celex_monosyllabic.txt'\n",
    "\n",
    "LOAD_MODEL = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.KeyedVectors.load_word2vec_format(MODEL_PATH, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "entries = open(ROOT_PATH, \"r\").read().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = [entry.split(\"\\\\\")[0] for entry in entries if entry != \"\" and entry.islower()]\n",
    "words[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter by words that appear in model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "critical_words = list(set([w for w in words if w in model.vocab]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2082"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(critical_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain form and meaning similarity metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we import the class `SystematicityUtilities` from a [custom library](https://github.com/seantrott/nlp_utilities). By default, this class uses *Levenshtein distance* as its metric for *form similarity*, and *cosine similarity* as its metric for *meaning similarity*. The `compare_form_and_meaning` method used below compares every word pair along form and meaning dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlp_utilities.compling import SystematicityUtilities\n",
    "systematicity_utils = SystematicityUtilities(model)\n",
    "comparisons = systematicity_utils.compare_form_and_meaning(critical_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparisons_df = pd.DataFrame.from_dict(comparisons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2166321 comparisons total\n"
     ]
    }
   ],
   "source": [
    "print(\"{length} comparisons total\".format(length=len(comparisons_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>form</th>\n",
       "      <th>meaning</th>\n",
       "      <th>w1</th>\n",
       "      <th>w2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1567657</th>\n",
       "      <td>1</td>\n",
       "      <td>0.199551</td>\n",
       "      <td>joy</td>\n",
       "      <td>boy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501172</th>\n",
       "      <td>1</td>\n",
       "      <td>0.089559</td>\n",
       "      <td>dorm</td>\n",
       "      <td>corm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1164769</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.003794</td>\n",
       "      <td>coax</td>\n",
       "      <td>hoax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1247141</th>\n",
       "      <td>1</td>\n",
       "      <td>0.266609</td>\n",
       "      <td>hap</td>\n",
       "      <td>ha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422626</th>\n",
       "      <td>1</td>\n",
       "      <td>0.094712</td>\n",
       "      <td>clap</td>\n",
       "      <td>claw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2077351</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.002984</td>\n",
       "      <td>ask</td>\n",
       "      <td>asp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1209026</th>\n",
       "      <td>1</td>\n",
       "      <td>0.032284</td>\n",
       "      <td>plan</td>\n",
       "      <td>clan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501166</th>\n",
       "      <td>1</td>\n",
       "      <td>0.081128</td>\n",
       "      <td>dorm</td>\n",
       "      <td>doom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571643</th>\n",
       "      <td>1</td>\n",
       "      <td>0.151699</td>\n",
       "      <td>fab</td>\n",
       "      <td>fay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988738</th>\n",
       "      <td>1</td>\n",
       "      <td>0.059454</td>\n",
       "      <td>wide</td>\n",
       "      <td>wipe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         form   meaning    w1    w2\n",
       "1567657     1  0.199551   joy   boy\n",
       "501172      1  0.089559  dorm  corm\n",
       "1164769     1 -0.003794  coax  hoax\n",
       "1247141     1  0.266609   hap    ha\n",
       "422626      1  0.094712  clap  claw\n",
       "2077351     1 -0.002984   ask   asp\n",
       "1209026     1  0.032284  plan  clan\n",
       "501166      1  0.081128  dorm  doom\n",
       "571643      1  0.151699   fab   fay\n",
       "1988738     1  0.059454  wide  wipe"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparisons_df.sort_values('form').head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import linregress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r=-0.040672612879521675, p=0.0\n"
     ]
    }
   ],
   "source": [
    "true_regression = linregress(comparisons_df['form'], comparisons_df['meaning'])\n",
    "print(\"r={r}, p={p}\".format(r=true_regression.rvalue, p=true_regression.pvalue))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In other words, words with higher **form distance** (e.g. a higher Levenshtein distance) will have smaller **meaning similarity** (e.g. cosine similarity)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare global correlation to permuted distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "permuted_results = []\n",
    "for permute in range(10):\n",
    "    permuted_meaning = np.random.permutation(list(comparisons_df['meaning']))\n",
    "    random_regression = linregress(comparisons_df['form'], permuted_meaning)\n",
    "    permuted_results.append(random_regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "permuted_cors = [reg.rvalue for reg in permuted_results]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can compare the *true correlation* with the distribution of correlations obtained by shuffling our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "greater = [cor for cor in permuted_cors if cor <= true_regression.rvalue]\n",
    "p_global = len(greater) / len(permuted_cors)\n",
    "p_global"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Systematicity coefficients for each word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can use leave-one-out regression to determine how each word contributes to the overall correlation. For each word, we remove all comparisons involving that word, then take the global correlation again, and compare that score to the original correlation. This follows the procedure in [Monaghan et al, 2014](http://rstb.royalsocietypublishing.org/content/369/1651/20130299.short).\n",
    "\n",
    "Recall that **original** was negative. So if **original** - **new** is negative, that means that removing the word results in a *lower* correlation (e.g. closer to 0), which suggests that the word provided a source of **form-meaning systematicity** to the correlation.\n",
    "\n",
    "If **original** - **new** is positive, that means that removing the word results in a *higher* correlation (e.g. further from 0), which suggests that the word provided a source of **form-meaning arbitrariness** to the correlation.\n",
    "\n",
    "Thus:\n",
    "* **Negative** impact values suggest a word is more systematic\n",
    "* **Positive** impact values suggest a word is more arbitrary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_systematicity = {\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0% done...\n",
      "10.0% done...\n",
      "14.000000000000002% done...\n",
      "19.0% done...\n",
      "24.0% done...\n",
      "28.999999999999996% done...\n",
      "34.0% done...\n",
      "38.0% done...\n",
      "43.0% done...\n",
      "48.0% done...\n",
      "53.0% done...\n",
      "57.99999999999999% done...\n",
      "62.0% done...\n",
      "67.0% done...\n",
      "72.0% done...\n",
      "77.0% done...\n",
      "82.0% done...\n",
      "86.0% done...\n",
      "91.0% done...\n",
      "96.0% done...\n"
     ]
    }
   ],
   "source": [
    "index = 1\n",
    "for word in critical_words:\n",
    "    if index % 100 == 0:\n",
    "        print(\"{pct}% done...\".format(pct=round(index/len(critical_words), 2)*100))\n",
    "    df_copy = comparisons_df[(comparisons_df['w1'] != word) & (comparisons_df['w2'] != word)]\n",
    "    new_correlation = linregress(df_copy['form'], df_copy['meaning'])\n",
    "    word_to_systematicity[word] = true_regression.rvalue - new_correlation.rvalue\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2082"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_to_systematicity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0503107176006166e-05"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_systematicity['mute']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_systematicity_df = pd.DataFrame.from_dict({'word': list(word_to_systematicity.keys()),\n",
    "                                                 'impact': list(word_to_systematicity.values())})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>impact</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>pleased</td>\n",
       "      <td>-0.001439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>strained</td>\n",
       "      <td>-0.000916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2029</th>\n",
       "      <td>rights</td>\n",
       "      <td>-0.000891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>fraught</td>\n",
       "      <td>-0.000799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          word    impact\n",
       "583    pleased -0.001439\n",
       "438   strained -0.000916\n",
       "2029    rights -0.000891\n",
       "562    fraught -0.000799"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_systematicity_df.sort_values('impact').head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_systematicity_df['word_length'] = words_systematicity_df['word'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>impact</td>      <th>  R-squared:         </th>  <td>   0.014</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.014</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   30.51</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 04 Sep 2018</td> <th>  Prob (F-statistic):</th>  <td>3.74e-08</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>16:43:25</td>     <th>  Log-Likelihood:    </th>  <td>  15410.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  2082</td>      <th>  AIC:               </th> <td>-3.082e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  2080</td>      <th>  BIC:               </th> <td>-3.080e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>   <td> -7.94e-05</td> <td> 1.47e-05</td> <td>   -5.389</td> <td> 0.000</td> <td>   -0.000</td> <td>-5.05e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>word_length</th> <td> 1.822e-05</td> <td>  3.3e-06</td> <td>    5.524</td> <td> 0.000</td> <td> 1.18e-05</td> <td> 2.47e-05</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>670.324</td> <th>  Durbin-Watson:     </th> <td>   2.040</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>9327.518</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-1.120</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>13.125</td>  <th>  Cond. No.          </th> <td>    21.3</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                 impact   R-squared:                       0.014\n",
       "Model:                            OLS   Adj. R-squared:                  0.014\n",
       "Method:                 Least Squares   F-statistic:                     30.51\n",
       "Date:                Tue, 04 Sep 2018   Prob (F-statistic):           3.74e-08\n",
       "Time:                        16:43:25   Log-Likelihood:                 15410.\n",
       "No. Observations:                2082   AIC:                        -3.082e+04\n",
       "Df Residuals:                    2080   BIC:                        -3.080e+04\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===============================================================================\n",
       "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------\n",
       "Intercept    -7.94e-05   1.47e-05     -5.389      0.000      -0.000   -5.05e-05\n",
       "word_length  1.822e-05    3.3e-06      5.524      0.000    1.18e-05    2.47e-05\n",
       "==============================================================================\n",
       "Omnibus:                      670.324   Durbin-Watson:                   2.040\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             9327.518\n",
       "Skew:                          -1.120   Prob(JB):                         0.00\n",
       "Kurtosis:                      13.125   Cond. No.                         21.3\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ols(\"impact ~ word_length\", words_systematicity_df).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write data to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparisons_df.to_csv(\"data/processed/wordpair_comparisons.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_systematicity_df.to_csv(\"data/processed/all_words_systematicity.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
