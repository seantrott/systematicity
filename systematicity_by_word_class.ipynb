{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Systematicity in English monomorphemic words by word class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sean Trott"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do certain word classes have more sub-morphemic systematicity than others?\n",
    "\n",
    "**TO DO**:\n",
    "* Use Levenshtein distance over phonemes, instead of orthography\n",
    "* Relate to word features: grammatical class, AoA, Concreteness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import gensim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Variables\n",
    "MODEL_PATH = os.environ['WORD2VEC_PATH']\n",
    "ROOT_PATH = 'data/raw/roots_celex_monosyllabic.txt'\n",
    "\n",
    "LOAD_MODEL = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.KeyedVectors.load_word2vec_format(MODEL_PATH, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "entries = open(ROOT_PATH, \"r\").read().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = [entry.split(\"\\\\\")[0] for entry in entries if entry != \"\" and entry.islower()]\n",
    "words[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter by words that appear in model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "critical_words = list(set([w for w in words if w in model.vocab]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2082"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(critical_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain form and meaning similarity metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we import the class `SystematicityUtilities` from a [custom library](https://github.com/seantrott/nlp_utilities). By default, this class uses *Levenshtein distance* as its metric for *form similarity*, and *cosine similarity* as its metric for *meaning similarity*. The `compare_form_and_meaning` method used below compares every word pair along form and meaning dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlp_utilities.compling import SystematicityUtilities\n",
    "systematicity_utils = SystematicityUtilities(model)\n",
    "comparisons = systematicity_utils.compare_form_and_meaning(critical_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparisons_df = pd.DataFrame.from_dict(comparisons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2166321 comparisons total\n"
     ]
    }
   ],
   "source": [
    "print(\"{length} comparisons total\".format(length=len(comparisons_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>form</th>\n",
       "      <th>meaning</th>\n",
       "      <th>w1</th>\n",
       "      <th>w2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>395754</th>\n",
       "      <td>3</td>\n",
       "      <td>0.143498</td>\n",
       "      <td>down</td>\n",
       "      <td>post</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1057731</th>\n",
       "      <td>3</td>\n",
       "      <td>0.095133</td>\n",
       "      <td>rile</td>\n",
       "      <td>whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361919</th>\n",
       "      <td>5</td>\n",
       "      <td>0.181221</td>\n",
       "      <td>skirl</td>\n",
       "      <td>hole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217214</th>\n",
       "      <td>5</td>\n",
       "      <td>0.118652</td>\n",
       "      <td>smile</td>\n",
       "      <td>leek</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         form   meaning     w1     w2\n",
       "395754      3  0.143498   down   post\n",
       "1057731     3  0.095133   rile  whale\n",
       "361919      5  0.181221  skirl   hole\n",
       "217214      5  0.118652  smile   leek"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparisons_df.sample(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import linregress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.04067261287952176"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_regression = linregress(comparisons_df['form'], comparisons_df['meaning'])\n",
    "true_regression.rvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In other words, words with higher **form distance** (e.g. a higher Levenshtein distance) will have smaller **meaning similarity** (e.g. cosine similarity)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare global correlation to permuted distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "permuted_results = []\n",
    "for permute in range(10):\n",
    "    permuted_meaning = np.random.permutation(comparisons_df['meaning'])\n",
    "    random_regression = linregress(comparisons_df['form'], permuted_meaning)\n",
    "    permuted_results.append(random_regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "permuted_cors = [reg.rvalue for reg in permuted_results]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can compare the *true correlation* with the distribution of correlations obtained by shuffling our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "greater = [cor for cor in permuted_cors if cor <= true_regression.rvalue]\n",
    "p_global = len(greater) / len(permuted_cors)\n",
    "p_global"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Systematicity coefficients for each word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can use leave-one-out regression to determine how each word contributes to the overall correlation. For each word, we remove all comparisons involving that word, then take the global correlation again, and compare that score to the original correlation. This follows the procedure in [Monaghan et al, 2014](http://rstb.royalsocietypublishing.org/content/369/1651/20130299.short).\n",
    "\n",
    "Recall that **original** was negative. So if **original** - **new** is negative, that means that removing the word results in a *lower* correlation (e.g. closer to 0), which suggests that the word provided a source of **form-meaning systematicity** to the correlation.\n",
    "\n",
    "If **original** - **new** is positive, that means that removing the word results in a *higher* correlation (e.g. further from 0), which suggests that the word provided a source of **form-meaning arbitrariness** to the correlation.\n",
    "\n",
    "Thus:\n",
    "* **Negative** impact values suggest a word is more systematic\n",
    "* **Positive** impact values suggest a word is more arbitrary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_systematicity = {\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0% done...\n",
      "1.0% done...\n",
      "1.0% done...\n",
      "2.0% done...\n",
      "2.0% done...\n",
      "3.0% done...\n",
      "3.0% done...\n",
      "4.0% done...\n",
      "4.0% done...\n",
      "5.0% done...\n",
      "5.0% done...\n",
      "6.0% done...\n",
      "6.0% done...\n",
      "7.000000000000001% done...\n",
      "7.000000000000001% done...\n",
      "8.0% done...\n",
      "8.0% done...\n",
      "9.0% done...\n",
      "9.0% done...\n",
      "10.0% done...\n",
      "10.0% done...\n",
      "11.0% done...\n",
      "11.0% done...\n",
      "12.0% done...\n",
      "12.0% done...\n",
      "12.0% done...\n",
      "13.0% done...\n",
      "13.0% done...\n",
      "14.000000000000002% done...\n",
      "14.000000000000002% done...\n",
      "15.0% done...\n",
      "15.0% done...\n",
      "16.0% done...\n",
      "16.0% done...\n",
      "17.0% done...\n",
      "17.0% done...\n",
      "18.0% done...\n",
      "18.0% done...\n",
      "19.0% done...\n",
      "19.0% done...\n",
      "20.0% done...\n",
      "20.0% done...\n",
      "21.0% done...\n",
      "21.0% done...\n",
      "22.0% done...\n",
      "22.0% done...\n",
      "23.0% done...\n",
      "23.0% done...\n",
      "24.0% done...\n",
      "24.0% done...\n",
      "24.0% done...\n",
      "25.0% done...\n",
      "25.0% done...\n",
      "26.0% done...\n",
      "26.0% done...\n",
      "27.0% done...\n",
      "27.0% done...\n",
      "28.000000000000004% done...\n",
      "28.000000000000004% done...\n",
      "28.999999999999996% done...\n",
      "28.999999999999996% done...\n",
      "30.0% done...\n",
      "30.0% done...\n",
      "31.0% done...\n",
      "31.0% done...\n",
      "32.0% done...\n",
      "32.0% done...\n",
      "33.0% done...\n",
      "33.0% done...\n",
      "34.0% done...\n",
      "34.0% done...\n",
      "35.0% done...\n",
      "35.0% done...\n",
      "36.0% done...\n",
      "36.0% done...\n",
      "37.0% done...\n",
      "37.0% done...\n",
      "37.0% done...\n",
      "38.0% done...\n",
      "38.0% done...\n",
      "39.0% done...\n",
      "39.0% done...\n",
      "40.0% done...\n",
      "40.0% done...\n",
      "41.0% done...\n",
      "41.0% done...\n",
      "42.0% done...\n",
      "42.0% done...\n",
      "43.0% done...\n",
      "43.0% done...\n",
      "44.0% done...\n",
      "44.0% done...\n",
      "45.0% done...\n",
      "45.0% done...\n",
      "46.0% done...\n",
      "46.0% done...\n",
      "47.0% done...\n",
      "47.0% done...\n",
      "48.0% done...\n",
      "48.0% done...\n",
      "49.0% done...\n",
      "49.0% done...\n",
      "49.0% done...\n",
      "50.0% done...\n",
      "50.0% done...\n",
      "51.0% done...\n",
      "51.0% done...\n",
      "52.0% done...\n",
      "52.0% done...\n",
      "53.0% done...\n",
      "53.0% done...\n",
      "54.0% done...\n",
      "54.0% done...\n",
      "55.00000000000001% done...\n",
      "55.00000000000001% done...\n",
      "56.00000000000001% done...\n",
      "56.00000000000001% done...\n",
      "56.99999999999999% done...\n",
      "56.99999999999999% done...\n",
      "57.99999999999999% done...\n",
      "57.99999999999999% done...\n",
      "59.0% done...\n",
      "59.0% done...\n",
      "60.0% done...\n",
      "60.0% done...\n",
      "61.0% done...\n",
      "61.0% done...\n",
      "61.0% done...\n",
      "62.0% done...\n",
      "62.0% done...\n",
      "63.0% done...\n",
      "63.0% done...\n",
      "64.0% done...\n",
      "64.0% done...\n",
      "65.0% done...\n",
      "65.0% done...\n",
      "66.0% done...\n",
      "66.0% done...\n",
      "67.0% done...\n",
      "67.0% done...\n",
      "68.0% done...\n",
      "68.0% done...\n",
      "69.0% done...\n",
      "69.0% done...\n",
      "70.0% done...\n",
      "70.0% done...\n",
      "71.0% done...\n",
      "71.0% done...\n",
      "72.0% done...\n",
      "72.0% done...\n",
      "73.0% done...\n",
      "73.0% done...\n",
      "73.0% done...\n",
      "74.0% done...\n",
      "74.0% done...\n",
      "75.0% done...\n",
      "75.0% done...\n",
      "76.0% done...\n",
      "76.0% done...\n",
      "77.0% done...\n",
      "77.0% done...\n",
      "78.0% done...\n",
      "78.0% done...\n",
      "79.0% done...\n",
      "79.0% done...\n",
      "80.0% done...\n",
      "80.0% done...\n",
      "81.0% done...\n",
      "81.0% done...\n",
      "82.0% done...\n",
      "82.0% done...\n",
      "83.0% done...\n",
      "83.0% done...\n",
      "84.0% done...\n",
      "84.0% done...\n",
      "85.0% done...\n",
      "85.0% done...\n",
      "85.0% done...\n",
      "86.0% done...\n",
      "86.0% done...\n",
      "87.0% done...\n",
      "87.0% done...\n",
      "88.0% done...\n",
      "88.0% done...\n",
      "89.0% done...\n",
      "89.0% done...\n",
      "90.0% done...\n",
      "90.0% done...\n",
      "91.0% done...\n",
      "91.0% done...\n",
      "92.0% done...\n",
      "92.0% done...\n",
      "93.0% done...\n",
      "93.0% done...\n",
      "94.0% done...\n",
      "94.0% done...\n",
      "95.0% done...\n",
      "95.0% done...\n",
      "96.0% done...\n",
      "96.0% done...\n",
      "97.0% done...\n",
      "97.0% done...\n",
      "98.0% done...\n",
      "98.0% done...\n",
      "98.0% done...\n",
      "99.0% done...\n",
      "99.0% done...\n",
      "100.0% done...\n"
     ]
    }
   ],
   "source": [
    "index = 1\n",
    "for word in critical_words:\n",
    "    if index % 100 == 0:\n",
    "        print(\"{pct}% done...\".format(pct=round(index/len(critical_words), 2)*100))\n",
    "    df_copy = comparisons_df[(comparisons_df['w1'] != word) & (comparisons_df['w2'] != word)]\n",
    "    new_correlation = linregress(df_copy['form'], df_copy['meaning'])\n",
    "    word_to_systematicity[word] = true_regression.rvalue - new_correlation.rvalue\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2082"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_to_systematicity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_systematicity_df = pd.DataFrame.from_dict({'word': list(word_to_systematicity.keys()),\n",
    "                                                 'impact': list(word_to_systematicity.values())})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>impact</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>dark</td>\n",
       "      <td>-0.041383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949</th>\n",
       "      <td>wold</td>\n",
       "      <td>-0.041370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>price</td>\n",
       "      <td>-0.041344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1699</th>\n",
       "      <td>wave</td>\n",
       "      <td>-0.041352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word    impact\n",
       "20     dark -0.041383\n",
       "949    wold -0.041370\n",
       "474   price -0.041344\n",
       "1699   wave -0.041352"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_systematicity_df.sample(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_systematicity_df['word_length'] = words_systematicity_df['word'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>impact</th>\n",
       "      <th>word_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1858</th>\n",
       "      <td>tray</td>\n",
       "      <td>-0.041356</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>stark</td>\n",
       "      <td>-0.041328</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>brawl</td>\n",
       "      <td>-0.041373</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1207</th>\n",
       "      <td>dam</td>\n",
       "      <td>-0.041332</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word    impact  word_length\n",
       "1858   tray -0.041356            4\n",
       "630   stark -0.041328            5\n",
       "294   brawl -0.041373            5\n",
       "1207    dam -0.041332            3"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_systematicity_df.sample(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>impact</td>      <th>  R-squared:         </th>  <td>   0.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>  -0.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>  0.1737</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 04 Sep 2018</td> <th>  Prob (F-statistic):</th>   <td> 0.677</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>13:35:52</td>     <th>  Log-Likelihood:    </th>  <td>  19504.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  2082</td>      <th>  AIC:               </th> <td>-3.900e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  2080</td>      <th>  BIC:               </th> <td>-3.899e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>   <td>   -0.0413</td> <td> 2.06e-06</td> <td>-2.01e+04</td> <td> 0.000</td> <td>   -0.041</td> <td>   -0.041</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>word_length</th> <td> 1.924e-07</td> <td> 4.62e-07</td> <td>    0.417</td> <td> 0.677</td> <td>-7.13e-07</td> <td>  1.1e-06</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>13.379</td> <th>  Durbin-Watson:     </th> <td>   1.926</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  18.969</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.004</td> <th>  Prob(JB):          </th> <td>7.60e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.468</td> <th>  Cond. No.          </th> <td>    21.3</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                 impact   R-squared:                       0.000\n",
       "Model:                            OLS   Adj. R-squared:                 -0.000\n",
       "Method:                 Least Squares   F-statistic:                    0.1737\n",
       "Date:                Tue, 04 Sep 2018   Prob (F-statistic):              0.677\n",
       "Time:                        13:35:52   Log-Likelihood:                 19504.\n",
       "No. Observations:                2082   AIC:                        -3.900e+04\n",
       "Df Residuals:                    2080   BIC:                        -3.899e+04\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===============================================================================\n",
       "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------\n",
       "Intercept      -0.0413   2.06e-06  -2.01e+04      0.000      -0.041      -0.041\n",
       "word_length  1.924e-07   4.62e-07      0.417      0.677   -7.13e-07     1.1e-06\n",
       "==============================================================================\n",
       "Omnibus:                       13.379   Durbin-Watson:                   1.926\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               18.969\n",
       "Skew:                          -0.004   Prob(JB):                     7.60e-05\n",
       "Kurtosis:                       3.468   Cond. No.                         21.3\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ols(\"impact ~ word_length\", words_systematicity_df).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write data to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparisons_df.to_csv(\"data/processed/wordpair_comparisons.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_systematicity_df.to_csv(\"data/processed/all_words_systematicity.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge with AoA data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Monaghan et al, 2014](http://rstb.royalsocietypublishing.org/content/369/1651/20130299.short) found an inverse relationship between age of acquisition and systematicity. That is, words that were learned earlier were more systematic. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "aoa = pd.read_csv(\"data/raw/AoA.csv\", delim_whitespace=True)\n",
    "aoa['word'] = aoa['Word'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>AoA</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1391</th>\n",
       "      <td>REGRET</td>\n",
       "      <td>428</td>\n",
       "      <td>regret</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>ELECTRICITY</td>\n",
       "      <td>400</td>\n",
       "      <td>electricity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>937</th>\n",
       "      <td>JUSTIFICATION</td>\n",
       "      <td>603</td>\n",
       "      <td>justification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>INSTANCE</td>\n",
       "      <td>471</td>\n",
       "      <td>instance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Word  AoA           word\n",
       "1391         REGRET  428         regret\n",
       "540     ELECTRICITY  400    electricity\n",
       "937   JUSTIFICATION  603  justification\n",
       "887        INSTANCE  471       instance"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aoa.sample(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "348"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aoa_plus_systematicity = pd.merge(words_systematicity_df, aoa)\n",
    "len(aoa_plus_systematicity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>impact</th>\n",
       "      <th>word_length</th>\n",
       "      <th>Word</th>\n",
       "      <th>AoA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>crime</td>\n",
       "      <td>-0.041339</td>\n",
       "      <td>5</td>\n",
       "      <td>CRIME</td>\n",
       "      <td>383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>girl</td>\n",
       "      <td>-0.041340</td>\n",
       "      <td>4</td>\n",
       "      <td>GIRL</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>male</td>\n",
       "      <td>-0.041365</td>\n",
       "      <td>4</td>\n",
       "      <td>MALE</td>\n",
       "      <td>383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>call</td>\n",
       "      <td>-0.041363</td>\n",
       "      <td>4</td>\n",
       "      <td>CALL</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      word    impact  word_length   Word  AoA\n",
       "50   crime -0.041339            5  CRIME  383\n",
       "262   girl -0.041340            4   GIRL  183\n",
       "42    male -0.041365            4   MALE  383\n",
       "173   call -0.041363            4   CALL  225"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aoa_plus_systematicity.sample(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>impact</td>      <th>  R-squared:         </th> <td>   0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>  -0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>  0.2202</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 04 Sep 2018</td> <th>  Prob (F-statistic):</th>  <td> 0.803</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>13:33:24</td>     <th>  Log-Likelihood:    </th> <td>  3267.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   348</td>      <th>  AIC:               </th> <td>  -6529.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   345</td>      <th>  BIC:               </th> <td>  -6518.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>   <td>   -0.0413</td> <td> 6.78e-06</td> <td>-6101.908</td> <td> 0.000</td> <td>   -0.041</td> <td>   -0.041</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AoA</th>         <td> 6.479e-10</td> <td> 1.06e-08</td> <td>    0.061</td> <td> 0.951</td> <td>-2.02e-08</td> <td> 2.15e-08</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>word_length</th> <td> 9.194e-07</td> <td> 1.44e-06</td> <td>    0.640</td> <td> 0.522</td> <td> -1.9e-06</td> <td> 3.74e-06</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 3.298</td> <th>  Durbin-Watson:     </th> <td>   2.033</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.192</td> <th>  Jarque-Bera (JB):  </th> <td>   3.124</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.162</td> <th>  Prob(JB):          </th> <td>   0.210</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.333</td> <th>  Cond. No.          </th> <td>2.34e+03</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                 impact   R-squared:                       0.001\n",
       "Model:                            OLS   Adj. R-squared:                 -0.005\n",
       "Method:                 Least Squares   F-statistic:                    0.2202\n",
       "Date:                Tue, 04 Sep 2018   Prob (F-statistic):              0.803\n",
       "Time:                        13:33:24   Log-Likelihood:                 3267.6\n",
       "No. Observations:                 348   AIC:                            -6529.\n",
       "Df Residuals:                     345   BIC:                            -6518.\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===============================================================================\n",
       "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------\n",
       "Intercept      -0.0413   6.78e-06  -6101.908      0.000      -0.041      -0.041\n",
       "AoA          6.479e-10   1.06e-08      0.061      0.951   -2.02e-08    2.15e-08\n",
       "word_length  9.194e-07   1.44e-06      0.640      0.522    -1.9e-06    3.74e-06\n",
       "==============================================================================\n",
       "Omnibus:                        3.298   Durbin-Watson:                   2.033\n",
       "Prob(Omnibus):                  0.192   Jarque-Bera (JB):                3.124\n",
       "Skew:                          -0.162   Prob(JB):                        0.210\n",
       "Kurtosis:                       3.333   Cond. No.                     2.34e+03\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 2.34e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ols(\"impact ~ AoA\", aoa_plus_systematicity).fit()\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
